<!doctype html>
<html lang="en" prefix="og: http://ogp.me/ns#">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- CLEAN MARKUP = GOOD KARMA.
      Hi source code lover,

      you're a curious person and a fast learner ;)
      Let's make something beautiful together. Contribute on Github:
      https://github.com/webslides/webslides

      Thanks!
      -->

    <!-- SEO -->
    <title>NoDaLiDa 2021</title>
    <meta name="description" content="WebSlides is the easiest way to create HTML presentations and landings. 120+ free slides ready to use.">

    <!-- URL CANONICAL -->
    <!-- <link rel="canonical" href="http://your-url.com/permalink"> -->

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,700,700i%7CMaitree:200,300,400,600,700&amp;subset=latin-ext" rel="stylesheet">

    <!-- CSS Base -->
    <link rel="stylesheet" type='text/css' media='all' href="webslides.css">

    <!-- Optional - CSS SVG Icons (Font Awesome) -->
    <link rel="stylesheet" type="text/css" media="all" href="../static/css/svg-icons.css">

    <!-- SOCIAL CARDS (ADD YOUR INFO) -->

    <!-- FACEBOOK -->
    <meta property="og:url" content="http://your-url.com/permalink"> <!-- EDIT -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="WebSlides Landings: Create your web presence easily"> <!-- EDIT -->
    <meta property="og:description" content="Create simple, beautiful landing pages with WebSlides. 120+ free slides ready to use."> <!-- EDIT -->
    <meta property="og:updated_time" content="2017-01-04T16:54:27"> <!-- EDIT -->
    <meta property="og:image" content="../static/images/share-webslides.jpg" > <!-- EDIT -->

    <!-- TWITTER -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@webslides"> <!-- EDIT -->
    <meta name="twitter:creator" content="@jlantunez"> <!-- EDIT -->
    <meta name="twitter:title" content="WebSlides Landings: Create your web presence easily"> <!-- EDIT -->
    <meta name="twitter:description" content="Create simple, beautiful landing pages with WebSlides. 120+ free slides ready to use."> <!-- EDIT -->
    <meta name="twitter:image" content="static/images/share-webslides.jpg"> <!-- EDIT -->

    <!-- FAVICONS -->
 

    <!-- Android -->
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="theme-color" content="#ffffff">
  </head>
  <body>
    <header role="banner">
      <nav role="navigation">
        <p class="logo"><a href="../index.html" title="WebSlides">WebSlides</a></p>
        <ul>
          <li class="github">
            <a rel="external" href="https://github.com/webslides/webslides" title="Github">
              <svg class="fa-github">
                <use xlink:href="#fa-github"></use>
              </svg>
              <em>WebSlides</em>
            </a>
          </li>
          <li class="twitter">
            <a rel="external" href="https://twitter.com/webslides" title="Twitter">
              <svg class="fa-twitter">
                <use xlink:href="#fa-twitter"></use>
              </svg>
              <em>@WebSlides</em>
            </a>
          </li>
          <!--  <li class="dribbble"><a rel="external" href="http://dribbble.com/webslides" title="Dribbble"><svg class="fa-dribbble"><use xlink:href="#fa-dribbble"></use></svg> <em>webslides</em></a></li> -->
        </ul>
      </nav>
    </header>
    <main role="main">
      <article id="webslides">

	<section style="background: #ffffff">
          <!--.wrap = container (width: 90%) -->
	  <div class="header" style="background: #47476b; color: #ffffff; padding:1.5em; margin-top: -8em; margin-left: -2em; margin-right: -2em; padding-bottom: 0.75em">
            <h2 style="margin-top: 0em; margin-left: 0.5em; font-variant: small-caps" align="left">What Taggers Fail to Learn, Parsers Need the Most
	      <img src="../IMG/UDC-Logo.png" alt="logo" style="margin-right:0.5em; background: #47476b; float: right; max-width: 120px; width: auto; display: block; max-height:95px; height: auto; margin-top:0.25em"/>
	      <img src="../IMG/citic.png" alt="logo" style="margin-right:0.5em; background: #47476b; float: right; max-width: 120px; width: auto; display: block; max-height:95px; height: auto; margin-top:0.3em"/>
	    </h2>
	  <h5 align="left" style="margin-top: -0.25em; margin-left:2.5em">Mark Anderson and Carlos Gómez-Rodríguez</h5>
	  </div>
	  <div class="wrap">
	   
            <div class="grid" style="margin-left:-5em; margin-right:-5em">
              <div class="column">
                <h3 class="text-content" style="color: #47476b">Motivation</h3>
                <p>Based on results from a previous paper (<a>On the Frailty of Universal POS Tags for Neural UD Parsers</a>, Anderson and Gómez-Rodríguez, 2020) where we observed a non-linear increase in performance when using gold-labelled POS tags instead of predicted tags, we wanted to investigate if this was due to the hard to predict POS tags being somehow more useful. We hypothesised that parsers learn something about word types implicitly and that taggers fail to capture the information that would be most useful for parsers. We used a BiLSTM biaffine GB parser throughout. And we used a linguistic-diverse subset of UD treebanks.</p>
		<h3 class="text-content" style="color: #47476b">Probing Experiment</h3>
		<p>We attempted a coarse probing experiment where we trained a parser and then fine-tuned a MLP using the frozen weights of the BiLSTM and embedding layers (Parser in Table 1). We trained BiLSTM taggers too (Tagger in Table 1) and also used the fine-tuning procedure on these as a sanity check (Tagger-FT in Table 1).</p>
		<div style="display:table-cell; vertical-align:middle; text-align:center">
		  <img src="img/table1.png" align="center"  width="350px">
		   <p><strong>Table 1:</strong> Tagging performance.</p>
		</div>
		<p style="margin-top: 2em">
		  <a>Table 1</a> shows the results for these 3 tagger systems.
		 The re-fine-tuned taggers achieve relatively similar performance to the original taggers, which suggests that this procedure does allow us to develop a decoder that captures what the BiLSTM and embedding layers learn about UPOS tags without adding new information. Clearly more training would likely improve the parsers fine-tuned for tagging, but it would be less clear if that would be extracting information the parser previously learnt or adding more information via MLP weights.
		</p>
		<p style="margin-top:-0.5em">
		 <a>Figure 1</a> shows the average union of errors across the treebanks, where only 38% of the tagger's errors don't occur for the parser.
		</p>		
              </div>
              <!-- end .column -->
              <div class="column">
                <div style="display:table-cell; vertical-align:middle; text-align:center">
		  <img src="../IMG/venn.png" align="center"  width="200px">
		  <p><strong>Figure 1:</strong> Average union of errors.</p>
		</div>
                <p style="margin-top: 2em">
		<a>Table 2</a> shows a break down of the parser fine-tuned to predict POS tags (Parser) and the system trained solely to predicted tags (Tagger) across all treebanks. The  number of tokens is also given to ground the scores.
		</p>
            
		<div style="display:table-cell; vertical-align:middle; text-align:center">
		  <img src="../IMG/tag-type-error.png" align="center"  width="400px">
		  <p><strong>Table 2:</strong> Tagging scores for different POS tags and different word classes.</p>
		</div>
		<p style="margin-top: 2em">
		  The ratio of the errors is substantially different for each class: 0.42 for <i>open</i>, 0.66 for <i>closed</i>, 0.78 for <i>other</i>. This perhaps suggests that the parser has a tendency to learn more syntactically fixed word types than open types.
		For the most part the parser is pretty close to the tagger for open class tags, except for <code>INTJ</code> which the parser never predicts, <code>PROPN</code> (32.7 less for the parser), and to a lesser extent <code>ADJ</code> (13.0 less). For the closed class type tags, again the parser performs similarly to the tagger but obtains a few points less except for <code>DET</code>, <code>NUM</code>, <code>PART</code>, and <code>PRON</code> with drops for parser scores of 7.9, 15.8, 13.6, and 23.9, respectively.
		</p>
              </div>
              <!-- end .column -->
              <div class="column">
                <h3 class="text-content" style="color: #47476b">Masking Experiment</h3>
		<p>Having established that parsers do learn something about word types and that there is a sizeable overlap with what it can predict and what <i>standard</i> taggers predict, we undertook a masking experiment to evaluate what impact these particular POS tags have for parsers. Results are shown in <a>Table 3</a>.</p>
		<p style="margin-top:-0.5em">We used a number of setting for the POS tags used for the parsers: no POS tags, <strong>None</strong>; predicted POS tags, <strong>Pred.</strong>; gold standard tags but with all tags masked except those predicted erroneously, <strong>M¬E<sub>T</sub></strong>;  with those predicted erronously by the fine-tuned parsers, <strong>M¬E<sub>P</sub></strong>; only those predicted correctly, <strong>M∀E<sub>T</sub></strong>; and all the gold standard tags, <strong>Gold</strong>. The same set of tags were used for training and inference.
		</p>

		<div style="display:table-cell; vertical-align:middle; text-align:center">
		  <img src="../IMG/masks.png" align="center"  width="400px">
		  <p><strong>Table 3:</strong> LAS for parsers in masking experiments.</p>
		</div>
		<p style="margin-top: 2em">
		  When masking everything but the errors, the average increase is about 2.5 over the no tag baseline and over 2 points better than using predicted tags. Interestingly the smaller set from the tagger outperforms the larger set from the parser by 0.15, suggesting that what both the taggers and the parsers fail to capture is more important than the errors unique to the parsers. When masking errors, the performance is almost 2 points better than using the predicted tags.</p>
                <h3 class="text-content" style="color: #47476b">Conclusion</h3>
                <p style=" margin-top: 0em">
		  We have presented results which suggest that parsers do learn something of word types and that what taggers fail to learn is needed to augment that knowledge.  We have shown that it would be more beneficial to implement taggers to not only predict tags but also decide when to do so, as the errors undermine anything gained from using predicted tags for dependency parsers.		  
		</p>
		<p style="margin-top:-1em">Paper available at <a>https://arxiv.org/abs/2104.01083</a></p>
              </div>
              <!-- end .column -->
            </div>
            <!-- end .grid -->
          </div>
          <!-- end .wrap -->
        </section>
      </article>
    </main>
    <!--main-->

    <!-- Required -->
    

    <script>
      window.ws = new WebSlides();
    </script>

 
  </body>
</html>
